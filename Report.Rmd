#Practical Machine Learning: Course project
###Author: Roman I Ozerov
##Initialization
```{r}
#Load libraries
library("caret")
```

##Load data
```{r}
#Download the data
if(!file.exists("pml-training.csv")){download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile = "pml-training.csv")}

if(!file.exists("pml-testing.csv")){download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", destfile = "pml-testing.csv")}

#Read the training data and replace empty values by NA
trainingDataSet<- read.csv("pml-training.csv", sep=",", header=TRUE, na.strings = c("NA","",'#DIV/0!'))
testingDataSet<- read.csv("pml-testing.csv", sep=",", header=TRUE, na.strings = c("NA","",'#DIV/0!'))
dim(trainingDataSet)
```
19622 values of 160 observations loaded.

##Cleanup data
Remove columns with missing values.
```{r}
trainingDataSet <- trainingDataSet[,(colSums(is.na(trainingDataSet)) == 0)]
dim(trainingDataSet)
testingDataSet <- testingDataSet[,(colSums(is.na(testingDataSet)) == 0)]
dim(testingDataSet)
```
Only 60 observations left

##Preprocess data
```{r}
numericalsIdx <- which(lapply(trainingDataSet, class) %in% "numeric")
preprocessModel <-preProcess(trainingDataSet[,numericalsIdx],method=c('knnImpute', 'center', 'scale'))
pre_trainingDataSet <- predict(preprocessModel, trainingDataSet[,numericalsIdx])
pre_trainingDataSet$classe <- trainingDataSet$classe
pre_testingDataSet <-predict(preprocessModel,testingDataSet[,numericalsIdx])
```

##Remove near-zero variables
Removing the variables with values near zero, that means that they have not so much meaning in the predictions
```{r}
nzv <- nearZeroVar(pre_trainingDataSet,saveMetrics=TRUE)
pre_trainingDataSet <- pre_trainingDataSet[,nzv$nzv==FALSE]
nzv <- nearZeroVar(pre_testingDataSet,saveMetrics=TRUE)
pre_testingDataSet <- pre_testingDataSet[,nzv$nzv==FALSE]
```

##Validation set
We want a 75% observation training dataset to train our model. We will then validate it on the last 70%.
```{r}
set.seed(12031987)
idxTrain<- createDataPartition(pre_trainingDataSet$classe, p=3/4, list=FALSE)
training<- pre_trainingDataSet[idxTrain, ]
validation <- pre_trainingDataSet[-idxTrain, ]
dim(training) ; dim(validation)
```

##Train Model
Train a model using random forest with a cross validation of 5 folds to avoid overfitting.
```{r}
library(randomForest)
modFitrf <- randomForest(classe ~., method="rf", data=training, trControl=trainControl(method='cv'), number=5, allowParallel=TRUE, importance=TRUE )
modFitrf
```

##Apply this model to 20 test cases provided
We have already clean the test data base (teData). We delete the "problem id" column as it is useless for our analysis.
```{r}
pred_final <- predict(modFitrf, pre_testingDataSet)
pred_final
```





